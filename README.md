**Project description:**
This project aims to properly clean the data over trees in New York City. This data contains 100000 entries with many parameters and information over these entries.
It is a 2 days project done in the context of improving knowlage in data cleaning.

**Installation and usage:**
In order to clean the data, it was used Jupyter Notebooks. Also 3 libaries where imported, namely pandas, numpy, and seaborn.

**Visuals:**
(tree diameter - trying to find outliers)

<img src="https://github.com/ltadrummond/nyc-trees/blob/main/plot.png" width="350">



**Time line:**
The first day of the project was occupied with setting up the Git repository localy and remotly. Also was important to understand the column names, what values they have, and what mesures where used. Looking at the data types, was also part of these day. It was also done striping, in order to bring conformity to the data.
On the second day, most of the work was done around detecting and fixing data redudancy. These were found and fixed mostly in columns related to naming of the trees, location, and problems. Also the tree id and index were removed, because for machine learning they wouldn't matter. Also fixed some dtypes again, and made a plot to look for outliers.
